# Project Glossary: AI and Machine Learning

This table provides a quick reference for the key terms and architectures used throughout this project.

| Term | Definition |
| :--- | :--- |
| **Autoregressive Integrated Moving Average (ARIMA)** | A time series forecasting model used to predict future data points by combining three components: autoregression, differencing, and moving averages. |
| **Bidirectional Encoder Representations from Transformers (BERT)** | A deep learning model in which every output element is connected to every input element. Weightings are dynamically calculated based on their connection. |
| **Computer Vision** | A field of AI that enables machines to interpret and understand visual information from various content such as images and videos. |
| **Convolutional Neural Networks (CNNs)** | A type of deep learning model designed to process and analyze visual data by automatically detecting patterns through convolutional layers. |
| **Cross-attention Mechanism** | A model that allows the model to focus on relevant parts of the input sequence while generating output. |
| **Decoder** | A neural network architecture used in NLP tasks like machine translation and text generation. It generates output by combining with an encoder to process input text. |
| **Deep Learning** | A branch of artificial intelligence (AI) that uses large, multi-layered neural networks to automatically learn and make predictions from complex data. |
| **Embed** | In transformers, the technique of converting input tokens into dense, continuous vectors that represent their semantic meaning within the model. |
| **Encoder** | Neural network layers that process the input sequence and produce a continuous representation of the input. |
| **Generative Pre-trained Transformers (GPT)** | Neural network-based language prediction models built on the Transformer architecture that analyze prompts to predict the best possible response. |
| **Image Processing** | A technique of manipulating and analyzing digital images to enhance, extract information, or convert them into a different format. |
| **Image Recognition** | A software's ability to identify and classify people, objects, places, writing, and actions in digital images and video. |
| **Layer Normalization** | A technique used in Transformer neural networks to normalize the input values of all neurons in a layer for each data sample. |
| **Long Short-Term Memory Networks (LSTMs)** | A type of recurrent neural network (RNN) designed to capture and maintain long-term dependencies in sequential data. |
| **Natural Language Generation** | The use of artificial intelligence to produce spoken or written human-like text. |
| **Natural Language Processing (NLP)** | Branch of artificial intelligence that enables computers to understand, manipulate, and generate human language. |
| **Parallelization** | In transformers, the ability to process multiple elements of a sequence simultaneously to speed up training and inference. |
| **Recurrent Neural Network (RNN)** | A deep learning model that is trained to process and convert a sequential data input into a specific sequential data output. |
| **Reinforcement Learning** | An area of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards. |
| **Self-attention Mechanisms** | Mechanisms in transformers that allow each element of a sequence to dynamically weigh the importance of other elements to capture context. |
| **Sequence** | An ordered set of tokens, such as words, that are processed together as input to capture dependencies and contextual information. |
| **Sequential Data** | Data that is ordered in a specific sequence, where the arrangement matters, such as time series, audio, or text. |
| **Speech Recognition** | A technology that converts spoken language into text by analyzing and interpreting audio signals. |
| **Transformers** | A technology that can leverage self-attention mechanisms to process input data in parallel, making them highly efficient and powerful. |
| **Vision Transformers (ViTs)** | A type of neural network architecture that applies transformer models to image analysis, treating image patches as sequences. |
